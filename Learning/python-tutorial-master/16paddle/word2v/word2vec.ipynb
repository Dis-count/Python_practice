{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词的向量表征\n",
    "\n",
    "one-hot vector，即每个词被表示是一个实数向量，长度为字典大小，每个维度对应一个字典里的每个词，该词的维度是1，其他都是0.只是该表示的缺点是每个词本身的信息量都太小。这种表示方式没法表示“皇上”跟“黄袍”的近似关系，因为这两个词对应的one-hot vectors之间的距离，无论是欧式距离还是余弦相似度都太远了。\n",
    "\n",
    "这样词向量模型就出场了，通过词向量模型可以将one-hot vector映射到一个维度更低的实数向量（embedding vector）,如“皇上”=[0.1,2.3,-2.1,...]，“黄袍”=[0.2,3.1,-1.3,...]。这样的实数向量中，两个语义上相似的词对应的词向量就“更像”了，“皇上”和“黄袍”的对应词向量的余弦就不再是零了。\n",
    "\n",
    "## 神经网络的词向量模型\n",
    "词向量模型可以是概率模型、共生矩阵(co-occurrence matrix)模型或神经元网络模型。我们选用基于神经网络的词向量模型，该模型通过学习语义信息得到词向量，可以解决之前的概率模型或者共生矩阵模型的矩阵稀疏问题、矩阵维度太高、需要去停用词等问题。\n",
    "\n",
    "## 训练词向量的模型\n",
    "训练词向量的模型有三个：N-gram模型，CBOW模型和Skip-gram模型。\n",
    "\n",
    "### N-gram neural model\n",
    "在计算语言学中，n-gram是一种重要的文本表示方法，表示一个文本中连续的n个项。基于具体的应用场景，每一项可以是一个字母、单词或者音节。 n-gram模型也是统计语言模型中的一种重要方法，用n-gram训练语言模型时，一般用每个n-gram的历史n-1个词语组成的内容来预测第n个词。\n",
    "\n",
    "这种条件概率建模语言模型，即一句话中的第t个词的概率和该句话的前t-1个词语相关。可实际上越远的词语其实对该词的影响越小，那么如果考虑一个n-gram，每个词只受前面n-1个词的影响。\n",
    "\n",
    "### Continuous Bag of Words model(CBOW）\n",
    "CBOW模型通过一个词的上下文（各N个词）预测当前词。当N=2时，是考虑上下文的词语输入顺序，CBOW是用上下文词语的词向量的均值预测当前词的。即：\n",
    "context=x-2 + x-1 + x+1 + x+2 / 4。\n",
    "\n",
    "### Skip-gram model\n",
    "CBOW的好处是对上下文词语的分布在词向量上平滑、去噪了，因此在小数据集上很有效。而在大数据集上，采用Skip-gram的方法更有效，因为Skip-gram的方法中，是用一个词预测其上下文，得到了当前词上下文的很多样本，因此可用于更大的数据集。\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}