def model(theta, X):
    """
    é¢„æµ‹å‡½æ•°
    :param theta: å‚æ•°çŸ©é˜µ(nx1)
    :param X:è¾“å…¥å˜é‡(çŸ©é˜µmxn)
    :return: è¾“å‡ºå˜é‡, mx1
    """
    return X.dot(theta)

def cost(m, theta, X, y):
    """
    ä»£ä»·å‡½æ•°
    :param m: è®­ç»ƒé›†ä¸ªæ•°
    :param theta: å‚æ•°çŸ©é˜µ(mx1)
    :param X: è¾“å…¥å˜é‡çŸ©é˜µ(mx1)
    :param y: è¾“å‡ºå˜é‡çŸ©é˜µ(mx1)
    :return:
    """
    ele = model(theta, X) - y
    item = ele ** 2
    item_sum = np.sum(item)
    return item_sum / (2 * m)

def derivative(m, theta, X, y, n):
    """
    å¯¹å„ä¸ªthetaå‚æ•°æ±‚å¯¼
    :param m: è®­ç»ƒé›†ä¸ªæ•°
    :param theta: å‚æ•°çŸ©é˜µ(nx1)
    :param X: è¾“å…¥å˜é‡çŸ©é˜µ(mxn)
    :param y: è¾“å‡ºå˜é‡çŸ©é˜µ(mx1)
    :param n: ðœƒå˜é‡ä¸ªæ•°ðœƒ0, ðœƒ1, ðœƒ2, ..., ðœƒn-1
    :return: nx1 çŸ©é˜µ
    """
    grad_theta = []
    for j in range(n):
        # å¯¹æ‰€æœ‰ðœƒjå˜é‡æ±‚å¯¼
        grad = (model(theta, X) - y).T.dot(X[:, j])
        grad_sum = np.sum(grad)
        grad_theta.append(grad_sum / m)
    return np.array(grad_theta).reshape(n, 1)

def gradient(grade_theta, theta, alpha):
    """
    ðœƒæ›´æ–°
    :param grade_theta:æ±‚å¯¼åŽçš„ðœƒçŸ©é˜µ(nx1)
    :param theta: æ›´æ–°åŽçš„ðœƒçŸ©é˜µ(nx1)
    :param alpha: å­¦ä¹ çŽ‡
    :return: è¿”å›žæ›´æ–°åŽçš„ðœƒçŸ©é˜µ(nx1)
    """
    return theta - alpha * grade_theta

def stop_strage(cost, cost_update, threshold):
    """
    åœæ­¢è¿­ä»£æ¡ä»¶
    :param cost:
    :param cost_update:
    :param threshold:
    :return:
    """
    return (cost >= cost_update) and (cost - cost_update < threshold)

def linear_regression(X, y):
    """
    çº¿æ€§å›žå½’æ¨¡åž‹
    :param X: è¾“å…¥å˜é‡çŸ©é˜µ(mxn)
    :param y: è¾“å‡ºå˜é‡çŸ©é˜µ(mx1)
    :param threshold:
    :return:
    """
    start = time.clock()
    m = X.shape[0] # æ ·æœ¬ä¸ªæ•°
    n = X.shape[1]
    theta = np.zeros(n).reshape(n, 1) # è®¾ç½®æƒé‡å‚æ•°çš„åˆå§‹å€¼
    y = y.reshape(m, 1)
    print "theta:", theta.shape, ", X: ", X.shape, "y:", y.shape

    cost_record = [] # è®°å½•ä»£ä»·å‡½æ•°çš„å€¼
    alpha = 0.0001 # å­¦ä¹ çŽ‡
    threshold = 0.01
    cost_val = cost(m, theta, X, y)

    cost_record.append(cost_val)

    iters = 0
    while True:
        grad = derivative(m, theta, X, y, n)
        # æƒé‡å‚æ•°æ›´æ–°
        theta = gradient(grad, theta, alpha)
        cost_update = cost(m, theta, X, y)
        if stop_strage(cost_val, cost_update, threshold):
            break
        cost_val = cost_update
        cost_record.append(cost_val)
        iters += 1
    end = time.clock()
    print("cost time: %f s" % (end - start))

    return cost_record, theta, iters

# ä½¿ç”¨è®­ç»ƒçº¿æ€§å›žå½’æ¨¡åž‹é¢„æµ‹æˆ¿ä»·
df = pd.read_csv('house_price.csv')

print df['rooms'].unique()
print df['halls'].unique()

# åŽ»é™¤è„æ•°æ®
keep_index = (df['rooms'] != 'å¤š') & (df['halls'] != 'å¤š')
df = df[keep_index]

# è½¬æ¢æ•°æ®ç±»åž‹
df['rooms'] = df['rooms'].astype('int')
df['halls'] = df['halls'].astype('int')

# æˆªå–roomsã€hallsã€sizeå’Œprice
X = df[['rooms', 'halls', 'size']]
y = df['price']

cost_record, theta, iters = linear_regression(X.values, y.values)
print iters
print theta
print cost_record

# é¢„æµ‹æ•°æ®
# rooms,halls,size,price
# 1,1,49,326
# 2,1,56.45,315
# 2,1,58.3,466
# 3,1,92.33,1061
# 2,1,76.88,408

print model(theta, np.array([1, 1, 49]))
print model(theta, np.array([2, 1, 56.45]))
print model(theta, np.array([2, 1, 58.3]))
print model(theta, np.array([3, 1, 92.33]))
print model(theta, np.array([2, 1, 76.88]))
